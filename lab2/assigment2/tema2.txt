1. Create topic a topic having 3 brokers as --bootstrap-server. 
The brokers' ports are taken from the docker-compose_kafka.yml
The topic should have 3 partitions and replication-factor 3
The name of the topic is events1. 
/usr/bin/kafka-topics --create --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --replication-factor 3 --partitions 3 --topic events1

Create a second topic having 3 brokers as --bootstrap-server. 
The brokers' ports are taken from the docker-compose_kafka.yml
The topic should have 4 partitions and replication-factor 2
The name of the topic is events2. 	
/usr/bin/kafka-topics --create --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --replication-factor 2 --partitions 4 --topic events2

2. List all topics 
/usr/bin/kafka-topics --list --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094

3. Send data. Create a Producer and send data to events2 topic, using key and ',' as separator.
/usr/bin/kafka-console-producer --broker-list kafka:19092,kafka2:19093,kafka3:19094 --topic events2 --property parse.key="true" --property key.separator=","

3. Read the data. Create a Consumer and read data from events2 topic.  
No data will be shown because we do not have --from-beginning property
docker exec -ti kafka /usr/bin/kafka-console-consumer --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --topic events2 --property print.key="true" --property key.separator=","

4. Run consumer and print the partition
Check that messages with the same key go to the same partition. Notice, that messages may come in a different order, when they are in different partitions.
docker exec -ti kafka /usr/bin/kafka-console-consumer --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --topic events2 --property print.partition="true" --property print.key="true" --property key.separator=","

5. Run with specifying consumer group and printing the partition and the offset
Check that messages with the same key go to the same partition. Notice, that messages may come in a different order, when they are in different partitions.
docker exec -ti kafka /usr/bin/kafka-console-consumer --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --topic events2 --group 1 --property print.partition="true" --property print.offset="true" --property print.key="true" --property key.separator=","

6. Create a group of 2 consumers. 
Now we have two consumers within one group.
docker exec -ti kafka /usr/bin/kafka-console-consumer --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --topic events2 --group 1 --property print.partition="true" --property print.offset="true" --property print.key="true" --property key.separator=","

7. Send more data with our producer
Check how the messages are distributed between the 2 consumers. 
Partitions 0 and 1 will apear on one consumer, and partitions 2 and 3 will apear on the second consumer.

8. Delete topic
docker exec -ti kafka /usr/bin/kafka-topics --delete --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --topic events1
docker exec -ti kafka /usr/bin/kafka-topics --delete --bootstrap-server kafka:19092,kafka2:19093,kafka3:19094 --topic events2
